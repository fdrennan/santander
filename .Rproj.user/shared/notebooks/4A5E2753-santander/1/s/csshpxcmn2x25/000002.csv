"0","models  = read_rds('models.rda')"
"0",""
"0","df_2_xgb <- function(data, target_col = NULL) {"
"0","  target_column = colnames(data) == target_col"
"0","  target = data[,target_column] %>% unlist"
"0","  target = as.integer(target)-1"
"0","  target_data = as.matrix(data[,!target_column])"
"0","  xgb.DMatrix("
"0","    data  = target_data,"
"0","    label= target"
"0","  )"
"0","}"
"0",""
"0","run_sample <- function(x) {"
"0","  "
"0","  train <-  x$train "
"0","  test <- x$test"
"0","  # Running a logistic regression"
"0","  if(FALSE) {"
"0","    model <- logistic_reg(penalty = 10, mixture = 0.1) %>% "
"0","      set_engine(""glm"") %>% "
"0","      fit(target ~ ., data = train)"
"0","  }"
"0","  "
"0","  if(FALSE) {"
"0","    model <- rand_forest(mtry = 12, trees = 2000) %>%"
"0","    set_engine(""ranger"", importance = 'impurity') %>%"
"0","    fit(target ~ ., data = train)"
"0","  }"
"0","  "
"0","  if(TRUE) {"
"0","    # train = mutate(train, target = as.integer(target))"
"0","    # target = Matrix::as.matrix(select(train,target)) - 1"
"0","    # train = Matrix::as.matrix(select(train,-target))"
"0","    "
"0","    # dtrain <- xgb.DMatrix(data = train, label = target)"
"0","    "
"0","    train.mat = df_2_xgb(train, 'target')"
"0","    valid.mat = df_2_xgb(test, 'target')"
"0","    "
"0","    params <-  list("
"0","        booster = ""gbtree"","
"0","        eta=0.3, "
"0","        # max_depth=6,  "
"0","        # gamma=0, "
"0","        # min_child_weight = 2, # [default=1]"
"0","        # max_delta_step = 0, # might help in logistic regression when class is extremely imbalanced. "
"0","        # subsample=.5,"
"0","        colsample_bytree=1,"
"0","        objective= ""reg:logistic"","
"0","        eval_metric = ""auc"", # logloss, auc, aucpr"
"0","        lambda = 1, # default 1"
"0","        alpha = 0, # default 0"
"0","        # num_class=2,"
"0","        tree_method = ""exact"", # auto, exact, approx, hist, gpu_exact, gpu_hist"
"0","        seed = 1"
"0","      )"
"0","    "
"0","    model=xgb.train("
"0","        params=params,"
"0","        data=train.mat,"
"0","        watchlist=list(val1=valid.mat),"
"0","        nrounds=500,"
"0","        nthreads=4,"
"0","        early_stopping_rounds=2,"
"0","        verbose=1)"
"0","   "
"0","  }"
"0","  "
"0","  model"
"0","  "
"0","}"
"0",""
"0","res = map("
"0","  models, run_sample"
"0",")"
"1","[1]	val1-auc:0.674342"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","val1_auc"
"1",""
"1"," hasn't improved in "
"1",""
"1","2"
"1",""
"1"," rounds.

"
"1","[2]	val1-auc:0.691785"
"1"," "
"1","
"
"1","[3]	val1-auc:0.714649"
"1"," "
"1","
"
"1","[4]	val1-auc:0.740363"
"1"," "
"1","
"
"1","[5]	val1-auc:0.757061"
"1"," "
"1","
"
"1","[6]	val1-auc:0.761687"
"1"," "
"1","
"
"1","[7]	val1-auc:0.762888"
"1"," "
"1","
"
"1","[8]	val1-auc:0.774076"
"1"," "
"1","
"
"1","[9]	val1-auc:0.772056"
"1"," "
"1","
"
"1","[10]	val1-auc:0.774940"
"1"," "
"1","
"
"1","[11]	val1-auc:0.786583"
"1"," "
"1","
"
"1","[12]	val1-auc:0.794770"
"1"," "
"1","
"
"1","[13]	val1-auc:0.786990"
"1"," "
"1","
"
"1","[14]	val1-auc:0.787529"
"1"," "
"1","
"
"1","Stopping. Best iteration:
"
"1",""
"1","[12]	val1-auc:0.794770"
"1",""
"1","

"
